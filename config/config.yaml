defaults:  - _self_  - override hydra/hydra_logging: disabled  - override hydra/job_logging: disabled  hydra:  output_subdir: null  run:  
    dir: .

general:
  project: "SAT"
  run_name: "Pythia-6-8-512-dfs (Training on easy)"
  devices: [2]

tok_data:
  train_file: "../data/cdcl_easy.json"
  tokenizer_path: "${model.tokenizer_path}/tokenizer.json"

data:
  datapath: data
  train_file_easy: "cdcl_easy_train.json"
  val_file_easy: "cdcl_easy_val.json"
  train_file_medium: "cdcl_medium_train.json"
  val_file_medium: "cdcl_medium_val.json"
  train_file_hard: "cdcl_hard_train.json"
  val_file_hard: "cdcl_hard_val.json"
  train_data: "easy"
  num_train: 100000
  num_eval: 1000
  num_workers: 64

model:
  name: "Pythia-${model.n_layer}-${model.n_head}-${model.n_embd}-dfs"
  batch_size: 16
  accumulate_grad_batches: 4
  block_size: 1024
  epochs: 10
  n_layer: 6
  n_head: 8
  n_embd: 512
  vocab_size: 56
  padded_vocab_size: 56
  bos_id: 52
  eos_id: 55
  checkpoint_dir: "model/${dl_model.full_path}"
  tokenizer_path: "model/${dl_model.full_path}"

optimizer:
  warmup_steps: 500
  lr: 1e-4
  weight_decay: 0.01
  betas: [0.9, 0.999]

eval:
  config_path: "${model.checkpoint_dir}/model_config.json"
  num_examples: 128
  batch_size: 64
  eval_interval: 10
  results_dir: "data/eval_results/${model.name}"
  log_step_frequency: 50
  val_check_interval: 0.2
  callback_epoch_frequency: 1
  callback_acc_data_count: 20

dl_model:
  model_folder: "checkpoints"
  name: "EleutherAI/pythia-160m"
  full_path: "${dl_model.model_folder}/${dl_model.name}/"

convert_hf:
  in_path: "temp/${model.name}"
  out_path: "temp/hf_${model.name}"